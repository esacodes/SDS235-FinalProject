---
title: "Esa's Exploratory Analysis"
subtitle: "SDS 235 Final Project"
author: "Esa Schenck"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    fig_width: 7
    fig_height: 6
    fig_caption: true
    code_folding: show
    df_print: paged
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set Up

```{r}
library(tidyverse)
library(lubridate)
```

```{r}
us_covid <- read_csv("us.csv") %>% 
  mutate(cases_rate = (cases/328239523)*100000)

tidied_data <- read_csv("data_correct_dates.csv")
```

Here I'm putting the essential things that I need to load (e.g. the latest version of the data I'm working with, the packages being used) in order to continue. In order to keep the chronological format that is useful for me to organize my work with, I'll simply put copies of code chunks here when I realize they're essential, and then set the chronological code chunk to eval=FALSE. In addition, note that I'm setting most of the 'working' code to eval=FALSE so that it doesn't take forever to knit when I was only using something as scratchwork and am done with it now.


# Initial Loading & Setting Up Data

```{r}
data <- read_csv("Mental_Health_Care_in_the_Last_4_Weeks.csv")
```

```{r, eval=FALSE}
glimpse(data)
```

# What does the data look like?

To be honest, the formatting of this data somewhat confuses me and I feel as though I don't understand exactly what all of the variables and conditions are -- this will help fix that!

**Columns**

 - Indicator
 - Group
 - State
 - Subgroup
 - Phase
 - Time Period
 - Time Period Label
 - Time Period Start Date
 - Time Period End Date
 - Value
 - LowCI
 - HighCI
 - Confidence Interval
 - Quartile Range 
 - Suppression Flag *(mostly NA values)*


## What are the possible values for each column?

```{r, eval = FALSE}
#Used to find all of the following values (not actually relevant to any data analysis)
data %>% 
  #filter(`Time Period` == 13, Group == "By State") %>% 
  select("Time Period Start Date") %>% 
  distinct()
```

**Indicators**

The four indicators are:

 - Took Prescription Medication for Mental Health, Last 4 Weeks
 - Received Counseling or Therapy, Last 4 Weeks
 - Took Prescription Medication for Mental Health And/Or Received Counseling or Therapy, Last 4 Weeks
 - Needed Counseling or Therapy But Did Not Get It, Last 4 Weeks


**Groups**

The seven groups are:

 - National Estimate	
 - By Age	
 - By Sex	
 - By Presence of Symptoms of Anxiety/Depression	
 - By Race/Hispanic ethnicity	
 - By Education	
 - By State


**States**

The fifty-two 'states' are the entire US population ("United States"), Washington DC ("District of Columbia"), and the fifty US states.


**Subgroups**

The subgroups for each group are:

National Estimate	

- United States	

By Age	

 - 18 - 29 years				
 - 30 - 39 years				
 - 40 - 49 years				
 - 50 - 59 years				
 - 60 - 69 years				
 - 70 - 79 years				
 - 80 years and above	

By Sex	

 - Male				
 - Female				

By Presence of Symptoms of Anxiety/Depression	

 - Did not experience symptoms of anxiety/depression in the past 4 weeks	
  - Experienced symptoms of anxiety/depression in past 4 weeks			

By Race/Hispanic ethnicity	

 - Hispanic or Latino				
 - Non-Hispanic white, single race				
 - Non-Hispanic black, single race				
 - Non-Hispanic Asian, single race				
 - Non-Hispanic, other races and multiple races	

By Education	

 - Less than a high school diploma				
 - High school diploma or GED				
 - Some college/Associate's degree				
 - Bachelor's degree or higher

By State

 - District of Columbia
 - the 50 US states


**Phases**

The three (??) phases are:

 - 2				
 - *NA*			
 - -1
 
 
 **Time Periods**
 
 The sixteen time periods are:

| Period | Period Label     | Period Start Time               |
|-------:|:----------------:|:--------------------------------|
|     13 | 	Aug 19 - Aug 31 | 8/19/20 0:00                    |
|     14 | 	Sep 2 - Sep 14  | 9/2/20 0:00	                    |
|     15 | 	Sep 16 - Sep 28 | 9/16/20 0:00	                  |
|     16 | 	Sep 30 - Oct 12 | 9/30/20 0:00                    |
|     17 | 	Oct 14 - Oct 26 | 10/14/20 0:00			              |
|     18 | 	Oct 28 - Nov 9  | 10/28/20 0:00			              |
|     19 | 	Nov 11 - Nov 23 | 11/11/20 0:00			              |
|     20 | 	Nov 25 - Dec 7  | 11/25/20 0:00			              |
|     21 | 	Dec 9 - Dec 21  | 12/9/20 0:00 OR 12:00:00 AM     |
|     1  |  Dec 22 - Jan 5  | 12/22/20 0:00 OR 12:00:00 AM    |
|     22 |  Jan 6 - Jan 18  | 1/6/21 0:00 OR 12:00:00 AM      |
|     23 |	Jan 20 - Feb 1  | 01/20/2021 12:00:00 AM          |
|     24 |	Feb 3 - Feb 15  | 02/03/2021 12:00:00 AM          |
|     25 |	Feb 17 - Mar 1  | 02/17/2021 12:00:00 AM          |
|     26 |	Mar 3 - Mar 15  | 03/03/2021 12:00:00 AM          |
|     27 |	Mar 17 - Mar 29 | 03/17/2021 12:00:00 AM          |



# Map of the US

For this I'm using the packages `usmap`, tutorial from https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html

```{r}
library(ggplot2)
library(usmap)
library(RColorBrewer)
```

```{r, eval=FALSE}
#Reminding myself how to use usmap, mostly taken from tutorial
plot_usmap(regions = "states") + 
  labs(title = "US States",
       subtitle = "This is a blank map of the states of the US (mostly taken from tutorial)") + 
  theme(panel.background = element_rect(color = "black"))
```

```{r, eval=FALSE}
#Also just reminding myself how to use usmap package -- mostly taken from tutorial
plot_usmap(data = statepop, values = "pop_2015", color = "red") + 
  scale_fill_continuous(name = "Population (2015)", label = scales::comma) + 
  theme(legend.position = "right")
```

Let's say we want to look at the indicator "Took Prescription Medication for Mental Health, Last 4 Weeks" for each US state (and DC) in the first time period, 13

```{r}
#Help getting the fips code from https://www.littlemissdata.com/blog/usmap
#Turns out the usmap package won't work without a "state" or "fips" column... and I thought there was a state column but it wasn't working, so fips did the trick!
data_states <- data
data_states$fips <- fips(data_states$State)
```

-1575318.95
-872719.7
```{r}
#Getting the data I want for this
data_states_13_meds <- data_states %>% 
  filter(Indicator == "Took Prescription Medication for Mental Health, Last 4 Weeks",
         Group == "By State",
         `Time Period` == 13) %>% 
  select(fips, Value, State, Indicator) 
```
```{r}
#GETTING ALL OF THE CUSTOM VALUES

#Title and the total value for the united states
full_title <- data_states_13_meds$Indicator %>% head(1)
title <- str_sub(full_title, 1, -15)

national_value <- data_states %>% 
  filter(Indicator == "Took Prescription Medication for Mental Health, Last 4 Weeks",
         Group == "National Estimate",
         `Time Period` == 13) %>% 
  select(Value) %>% 
  head(1) %>% 
  as.numeric()


#Finding the correct color for the total national value
data_states_13_meds$color_lev <- as.numeric(cut(data_states_13_meds$Value, 9, ordered=TRUE))

num <- as.numeric(data_states_13_meds %>% 
  filter(Value == which.min(abs(data_states_13_meds$color_lev-national_value))) %>% select(color_lev))
national_color <- brewer.pal(9, "Blues")[num+1]
```

To do:

 - outline borders in black (hawaii)
 - labels
 - label ne states with lines??
 
```{r}
#Now adding the map
plot_usmap(data=data_states_13_meds, values = "Value", color = "white", labels = TRUE, label_color = "white") +  
  scale_fill_distiller(name = "Percent", palette = "Blues", direction = 1) + 
  theme(legend.position = c(.9, .3)) +
  labs(title = title) +
  annotate("text", x = 3000000, y = -1900000, label = "US Total") +
  annotate("point", x = 2825000, y = -2100000, size = 5, color = national_color) +
  annotate("text", x = 3100000, y = -2100000, label = paste(national_value, "%", sep=""))
```

 - Help with plot legend: https://www.statology.org/ggplot-legend-position/
 - Help getting the coordinates and using annotate on the map (I realized the coordinate system is different, so I had to compare the different coordinates to figure out where I could approximately place the legend): https://cran.r-project.org/web/packages/usmap/vignettes/advanced-mapping.html
 - Help with brewer color plot (to find the specific blues in the brewer "Blues" color palette): http://jenrichmond.rbind.io/post/idhtg-how-to-use-colour-palettes-with-ggplot/
  - https://stackoverflow.com/questions/26287864/picking-individual-colours-from-a-rcolorbrewer-palette-as-a-scale-colour-manual
  - http://adomingues.github.io/2015/09/24/finding-closest-element-to-a-number-in-a-list/
  - for bins: https://stackoverflow.com/questions/12979456/categorize-numeric-variable-into-group-bins-breaks and https://www.geeksforgeeks.org/divide-a-vector-into-ranges-in-r-programming-cut-function/ and https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cut
 - Help with annotation: https://ggplot2.tidyverse.org/reference/annotate.html


Just a map mostly copied from the example, for help finding the correct coordinates:
```{r, eval=FALSE}
#earthquakes
eq_transformed <- usmap_transform(earthquakes)

eq_transformed <- eq_transformed %>% 
  mutate(lonlat = paste(lon.1, ", ", lat.1))

plot_usmap() +
  geom_point(data = eq_transformed, aes(x = lon.1, y = lat.1, size = mag),
             color = "red", alpha = 0.25) +
  labs(title = "US Earthquakes",
       subtitle = "Source: USGS, Jan 1 to Jun 30 2019",
       size = "Magnitude") +
  geom_label(data = eq_transformed, aes(x = lon.1, y = lat.1, label = lonlat)) +
  theme(legend.position = "right")
```



# Data wrangling

## Accessing NYT COVID Data from GitHub
"Data from The New York Times, based on reports from state and local health agencies." https://github.com/nytimes/covid-19-data/blob/master/README.md

```{r, eval=FALSE}
us_covid <- read_csv("us.csv")
```

## Cases per 100k

It'd be great if we could use the rolling averages one because it has per 100k people, but that is, um, a *rolling average*, which doesn't work so well for changes over time... meaning we're also going to have to add population data to this, then wrangle a bit! Yay

Census estimates data from the US Government for July 2019, 
 - accessed at https://www.census.gov/newsroom/press-kits/2019/national-state-estimates.html -- 
 - They give the citation: "Estimates of the Total Resident Population and Resident Population Age 18 Years and Older for the United States, States, and Puerto Rico: July 1, 2019 (SCPRC-EST2019-18+POP-RES)
 Source: U.S. Census Bureau, Population Division			
 Release Date: December 2019			
 - In addition, they give the note: "Note: The estimates are based on the 2010 Census and reflect changes to the April 1, 2010 population due to the Count Question Resolution program and geographic program revisions. See Geographic Terms and Definitions at https://www.census.gov/programs-surveys/popest/guidance-geographies/terms-and-definitions.html for a list of the states that are included in each region.  All geographic boundaries for the 2019 population estimates series except statistical area delineations are as of January 1, 2019.  For population estimates methodology statements, see https://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html.  The estimates add births to, subtract deaths from, and add net migration to the enumerated resident population from the 2010 Census.  The enumerated resident population is the total population (citizen and noncitizen) with usual residence in the 50 states and the District of Columbia.  See https://www.census.gov/glossary/#term_Apportionmentpopulation and https://www.census.gov/glossary/#term_Residentpopulation."
 - I renamed the file because it was very wordy to "Census-EST2019.xlsx", then reformatted the excel file so that it would save as a .csv and converted it; the original file title was "SCPRC-EST2019-18+POP-RES": Estimates of the Total Resident Population and Resident Population Age 18 Years and Older for the United States, States, and Puerto Rico: July 1, 2019
 
```{r, eval=FALSE}
us_pop <- read_csv("Census-EST2019.csv")
```


Apparently the total US population was 328,239,523.

To find rate per 100,000 people:
$rate = \frac{Cases}{Population} * 100,000$

In our case, the new variable `cases_rate` will equal 
$\frac{cases}{328239523}*100000$

```{r, eval=FALSE}
us_covid <- us_covid %>% 
  mutate(cases_rate = (cases/328239523)*100000)
```


## Tidying the time period format

Now I need to wrangle this into specific time frames!
These time frames will be based on the specific intervals listed in the main data under `Time Period Start Date`, and `Time Period End Date`.


```{r, eval=FALSE}
data %>% 
  select(`Time Period Start Date`, `Time Period End Date`) %>% 
  distinct()
```
```{r, eval=FALSE}
data %>% 
  filter(Group == "National Estimate") %>% 
  select(Indicator, `Time Period Start Date`, `Time Period End Date`, `Time Period Label`, Value)
```

Next, I need to find a way to group the us_covid data by the time periods in the mental health data.

get rid of the data before and after this time span
isolate the months and days
assign something based on if a value is true

But first, I realized that the main data abruptly switches date format

```{r, eval=FALSE}
end_date <- data %>% select(`Time Period End Date`)
lapply(end_date, class)
```


If else from https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/ifelse
```{r, eval=FALSE}
test <- data %>% 
  group_by(`Time Period Start Date`) %>% 
  mutate(Start_Date_1 = (ifelse(nchar(`Time Period Start Date`)==22, #if it's in the MM/DD/YYYY 12:00:00 AM format, then it takes the first ten characters
                                 str_sub(`Time Period Start Date`, 1, 10),
                                 ifelse(nchar(`Time Period Start Date`)==11, #now time for all of the wonderful ways the 0:00 dates can be -- up first, if it's got six characters for the date, e.g. M/D/YY, then take those first six characters
                                        str_sub(`Time Period Start Date`, 1, 6), 
                                        ifelse(nchar(`Time Period Start Date`)==12, #if it's got seven characters for the date, e.g. MM/D/YY or M/DD/YY, take seven
                                               str_sub(`Time Period Start Date`, 1, 7), #finally, if it's anything else then it has eight characters for the date, e.g. MM/DD/YY
                                               str_sub(`Time Period Start Date`, 1, 8))
                                        )
                                 )
                          )
         )
```


```{r, eval=FALSE}
data %>% mutate(try_to_substr = str_sub(`Time Period Start Date`, 1, 10))
```

**Did it work?**
```{r, eval=FALSE}
test %>% 
  distinct(Start_Date_1)
```
Looks like it worked!!!

PROBLEM FIGURED OUT: I was using length() instead of nchar() -- the former is the length of a vector, the latter is the number of characters in a string. It was returning "1" for all of the lengths, duh!!
nchar from https://stackoverflow.com/questions/11134812/how-to-find-the-length-of-a-string-in-r

**Figuring out how to use str_sub**
```{r, eval=FALSE}
am <- "12/21/2020 12:00:00 AM"
class(am)
paste("12/21/2020 12:00:00 AM has", nchar(am), "letters")
str_sub(am, 1, 10)

oo <- "9/28/20 0:00"
paste("9/28/20 0:00 has", nchar(oo), "letters")
str_sub(oo, 1, 7)

ooo <- "12/7/20 0:00"
paste("12/7/20 0:00 has ", nchar(ooo), "letters")
str_sub(ooo, 1, 7)

oooo <- "12/22/20 0:00"
paste("12/22/20 0:00 has ", nchar(oooo), "letters")

ifelse(nchar(oo)==12, str_sub(oo, 1, 7), str_sub(oo, 1, 8))

oo <- "12/7/20 0:00"
ifelse(nchar(oo)==12, str_sub(oo, 1, 7), str_sub(oo, 1, 8))

oo <- "12/22/20 0:00"
ifelse(nchar(oo)==12, str_sub(oo, 1, 7), str_sub(oo, 1, 8))

```

Okay, NOW we have to convert!!

```{r, eval=FALSE}
test %>% as.Date(Start_Date_1, format="%m %d %Y")
```

Fine, be obstinate and not work, see if I care!!

What's holding it up?
```{r, eval=FALSE}
library(lubridate)
```

```{r, eval=FALSE}
mdy(12/21/2020)
mdy(str_remove("12/21/2020", "/"))
mdy(12212020)
```

Now, going back to the code we had for the df `test`, let's see if we can make these dates!!

need to use str_remove_all for this: https://stackoverflow.com/questions/27044727/removing-characters-from-string-in-r
```{r, eval=FALSE}
test_2 <- data %>% 
  group_by(`Time Period Start Date`) %>% 
  mutate(Start_Date = (ifelse(nchar(`Time Period Start Date`)==22, #if it's in the MM/DD/YYYY 12:00:00 AM format, then it takes the first ten characters
                                 (str_remove_all(str_sub(`Time Period Start Date`, 1, 10), "/")),
                                 ifelse(nchar(`Time Period Start Date`)==11, #now time for all of the wonderful ways the 0:00 dates can be -- up first, if it's got six characters for the date, e.g. M/D/YY, then take those first six characters
                                        (str_remove_all(str_sub(`Time Period Start Date`, 1, 6), "/")), 
                                        ifelse(nchar(`Time Period Start Date`)==12, #if it's got seven characters for the date, e.g. MM/D/YY or M/DD/YY, take seven
                                               (str_remove_all(str_sub(`Time Period Start Date`, 1, 7), "/")), #finally, if it's anything else then it has eight characters for the date, e.g. MM/DD/YY
                                               (str_remove_all(str_sub(`Time Period Start Date`, 1, 8), "/"))
                                               )
                                        )
                                 )
                          ),
         start_date_new = mdy(Start_Date)
         )
```

Okay, that doesn't work when we add mdy() because of the variations in length -- if we try `mdy(str_remove_all("12/7/20", "/"))`, it doesn't work because it doesn't have enough characters to recognize. Is 12720 the date for 1/27/20 or 12/7/20? I need to find a way to... hmm might it recognize - instead of /?
```{r, eval=FALSE}
mdy("12-7-20")
```
Yes! HAHA it works!! So instead of str_remove_all, we need str_replace_all!

```{r, eval=FALSE}
test2 <- data %>% 
  group_by(`Time Period Start Date`) %>% 
  mutate(Start_Date = (ifelse(nchar(`Time Period Start Date`)==22, #if it's in the MM/DD/YYYY 12:00:00 AM format, then it takes the first ten characters
                                 (str_replace_all(str_sub(`Time Period Start Date`, 1, 10), "/", "-")),
                                 ifelse(nchar(`Time Period Start Date`)==11, #now time for all of the wonderful ways the 0:00 dates can be -- up first, if it's got six characters for the date, e.g. M/D/YY, then take those first six characters
                                        (str_replace_all(str_sub(`Time Period Start Date`, 1, 6), "/", "-")), 
                                        ifelse(nchar(`Time Period Start Date`)==12, #if it's got seven characters for the date, e.g. MM/D/YY or M/DD/YY, take seven
                                               (str_replace_all(str_sub(`Time Period Start Date`, 1, 7), "/", "-")), #finally, if it's anything else then it has eight characters for the date, e.g. MM/DD/YY
                                               (str_replace_all(str_sub(`Time Period Start Date`, 1, 8), "/", "-"))
                                               )
                                        )
                                 )
                          ),
         start_date_new = mdy(Start_Date)
         )
```


IT WORKED IT WORKED IT WORKED!!

Now we just need to get end dates on it!!

Okay, I'm done typing out this long ifelse statement, time to write a *function*!

```{r, eval=FALSE}
tidy_dates <- function(column){

mdy(ifelse(nchar(column)==22, #if it's in the MM/DD/YYYY 12:00:00 AM format, then it takes the first ten characters
                                 (str_replace_all(str_sub(column, 1, 10), "/", "-")),
                                 ifelse(nchar(column)==11, #now time for all of the wonderful ways the 0:00 dates can be -- up first, if it's got six characters for the date, e.g. M/D/YY, then take those first six characters
                                        (str_replace_all(str_sub(column, 1, 6), "/", "-")), 
                                        ifelse(nchar(column)==12, #if it's got seven characters for the date, e.g. MM/D/YY or M/DD/YY, take seven
                                               (str_replace_all(str_sub(column, 1, 7), "/", "-")), #finally, if it's anything else then it has eight characters for the date, e.g. MM/DD/YY
                                               (str_replace_all(str_sub(column, 1, 8), "/", "-"))
                                               )
                                        )
                                 ))
}
```

```{r, eval=FALSE}
data_correct_dates <- data %>% 
  group_by(`Time Period Start Date`) %>% 
  mutate(Start_Date = tidy_dates(`Time Period Start Date`),
         End_Date = tidy_dates(`Time Period End Date`))
```

write_csv from https://www.statology.org/export-data-frame-to-csv-in-r/
```{r, eval=FALSE}
write_csv(data_correct_dates, "data_correct_dates.csv")
```

```{r, eval=FALSE}
tidied_data <- read_csv("data_correct_dates.csv")
```


## Joining with covid data

### First, creating time intervals in the nyt covid data

What ARE the time intervals in the tidied data?
```{r, eval=FALSE}
tidied_data %>% 
  group_by(`Time Period`) %>% 
  select(`Time Period`, `Time Period Label`) %>% 
  distinct()
```

|Time Periods     |Time Period Label| Month |
|----------------:|:----------------|:------|
|Aug 19 - Aug 31 2020	|	13 | 8
|Sep 2 - Sep 14 2020  | 14 | 9
|Sep 16 - Sep 28 2020	|	15| 9
|Sep 30 - Oct 12 2020	|	16| 9 - 10
|Oct 14 - Oct 26 2020	|	17| 10
|Oct 28 - Nov 9 2020	| 18| 10 - 11
|Nov 11 - Nov 23 2020	|	19| 11
|Nov 25 - Dec 7 2020	| 20| 11 - 12
|Dec 9 - Dec 21 2020	| 21| 12
|Dec 22 - Jan 5 2021  | 1 | 12 - 1
|Jan 6 - Jan 18 2021	| 22| 1
|Jan 20 - Feb 1 2021	| 23| 1 - 2
|Feb 3 - Feb 15 2021	| 24| 2 
|Feb 17 - Mar 1 2021	| 25| 2 - 3 
|Mar 3 - Mar 15 2021	| 26| 3
|Mar 17 - Mar 29 2021 | 27| 3

First have to break the dates down into these intervals.

Sep 30 - Oct 12 2020	|	16| 9 - 10
|Oct 14 - Oct 26 2020	|	17| 10
|Oct 28 - Nov 9 2020	| 18| 10 - 11

FIGURE OUT YEAR -- IT MIGHT HAVE DUPLICATES BC OF MONTH
```{r}
sort_dates <- function(date){
  month = month(date)
  day = day(date)
  
  if ((month > 3) & (month < 8)) {NA} else {
    if (month == 8) {13} else {
      #sept: 2-14 is 14, 16-28 is 15, 30 is 16
      if (month == 9) {
        if ((day >= 2) & (day <= 14)) {14} else {
          if ((day >= 16) & (day <= 28)) {15} else {
            if (day == 30) {16} else {
              NA
            }
          }
        }
      } else {
        #oct: 1-12 is 16, 14-26 is 17, 28 - 31 is 18
      }
    }
  }

  
}
```

```{r}
sort_dates("2020-8-22")
```
References:

 - if else statements: https://www.datamentor.io/r-programming/if-else-statement/
 - & operator https://www.r-bloggers.com/2010/12/logical-operators-in-r/

# Fun time: confidence intervals and color palette??

```{r}
#min(tidied_data$Value)
tidied_data %>% 
  select(-`Quartile Range`, -`Suppression Flag`, -Phase) %>% 
  na.omit() %>% 
  #group_by(Group) %>% 
  summarise(min = min(HighCI-LowCI),
            max = max(HighCI-LowCI))
```

Okay, there really seems to be some variation in confidence intervals!! That indicates that it might be worth trying to use those value-suppressing uncertainty palettes!!